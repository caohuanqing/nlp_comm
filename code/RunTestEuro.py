import osimport tensorflow as tfimport numpy as npfrom SentenceBatchGenerator import SentenceBatchGenerator, Word2Numbfrom EncDecChanModels import Configfrom SentenceEncChanDecNet import generate_tb_filename, SimpleSystemdef test_on_euro_testset(sysNN,test_results_path):    # =============================  Validate on Test Data ===============================    sysNN.test_data.prepare_batch_queues(randomize=False)    batch = sysNN.test_data.get_next_batch(randomize=False)    acc_list = []    with open(test_results_path, 'w', newline='') as file:        while batch != None:            lr = sysNN.config.lr            fd = sysNN.next_feed(batch, lr, isTrain=False, help_prob = 0.0,                                keep_rate=sysNN.config.chan_params["keep_prob"])            predict_, accu_ = sess.run([sysNN.decoder.dec_pred, sysNN.accuracy], fd)            acc_list.append(accu_)            for i, (inp, pred) in enumerate(zip(fd[sysNN.enc_inputs], predict_)):                tx = " ".join(sysNN.word2numb.convert_n2w(inp))                rx = " ".join(sysNN.word2numb.convert_n2w(pred))                if i < 3:                    print('  sample {}:'.format(i + 1))                    print('TX: {}'.format(tx))                    print('RX: {}'.format(rx))                file.write('TX: {}\n'.format(tx))                file.write('RX: {}\n'.format(rx))            batch = sysNN.test_data.get_next_batch(randomize=False)        print("Average Accuracy: ", np.average(acc_list))        file.write("Average Accuracy: {}\n".format(np.average(acc_list)))    returnif __name__ == '__main__':    chan_params = {"type": "erasure", "keep_prob": 1.0}    parent_dir, _ = os.path.split(os.getcwd())    # parent_dir = os.getcwd()    print(parent_dir)    print('Init and Loading Data...')    config = Config(None,chan_params, lr=0.001, peephole=True)    # config = Config(None, chan_params)    resultsPath = generate_tb_filename(config)    modelPath = "Chan-erasure0.9-lr-0.001-txbits-500-voc-19158-embed-50-lstm-256-peep-True-epochs-30-bs-128-SOSdata-EuroSentence-Binarizer-HardAttn-0EncLayers-1-DecLayers-1"    model_save_path = os.path.join(parent_dir, 'trained_models', 'Vocab-19158', modelPath)    test_results_path = os.path.join(parent_dir, 'test_results', resultsPath + ".txt")    config.model_save_path=model_save_path    word2numb = Word2Numb(config.w2n_path)    train_sentence_gen = None    test_sentences = SentenceBatchGenerator(config.testdata_path,                                            word2numb,                                            config.batch_size,                                            config.length_from,                                            config.length_to,                                            config.bin_len,                                            config.UNK)    print('Done!')    print('Building Network...')    simp_sys = SimpleSystem(config, train_sentence_gen, test_sentences, word2numb)    print('Done!')    print('Start session...')    with tf.Session() as sess:        sess.run(tf.global_variables_initializer())        simp_sys.saver.restore(sess, model_save_path)        test_on_euro_testset(simp_sys, test_results_path)